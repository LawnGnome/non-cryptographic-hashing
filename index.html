<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Non-cryptographic hashing</title>

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/fonts.css">
		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="css/sky.css" id="theme">

    <!-- CSS overrides -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet/less" type="text/css" href="less/animate.less">
    <link rel="stylesheet/less" type="text/css" href="less/flowchart.less">

    <script src="less.min.js"></script>

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="reveal.js/lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<div class="slides">
				<section class="title">
          <h1>Non-cryptographic hashing</h1>
          <h3>
            Adam Harvey
            <br>
            <a href="https://twitter.com/LGnome">@LGnome</a>
            <br>
            <a href="http://newrelic.com">New Relic</a>
          </h3>
				</section>

        <section>
          <section>
            <h1>What?</h1>
          </section>

          <section>
            <h2>Hash function</h2>
            <aside class="notes">
              Let's start with the obvious: what is a hash function? (Most of
              you likely know this already, but let's make sure we're all on
              the same page.
            </aside>
          </section>

          <section class="input-output">
            <div class="input scroll-4">
              <div>
                <code>Lorem ipsum dolor sit amet,</code>
                <code>consectetur adipiscing elit.</code>
                <code>Integer vitae ex nec nisl</code>
                <code>fermentum sodales in ut lectus.</code>
              </div>
            </div>
            <div style="font-size: 2em">
              <span class="octicon mega-octicon octicon-arrow-down"></span>
            </div>
            <div class="output cycle-4">
              <code>61df8894</code>
              <code>0ec572f8</code>
              <code>19e37640</code>
              <code>372ecf1b</code>
            </div>
            <aside class="notes">
              Fundamentally, a hash function takes any amount of data and
              returns a number based on that data.
            </aside>
          </section>

          <section>
            <h2 id="hash-functions">
              <code>MD5</code>
              <code>SHA-1</code>
              <code>SHA-256</code>
              <code>SHA-512</code>
            </h2>
            <aside class="notes">
              We use them every day. They underpin SSL, block encryption,
              password storage, and many other things that we take for granted.
            </aside>
          </section>

          <section>
            <h2><strong style="opacity: 0">Non-</strong>Cryptographic hash function</h2>
            <aside class="notes">
              All of those are cryptographic hash functions, though. They're
              designed with specific qualities in mind: to make it as difficult
              as possible to generate collisions and to be able to work back to
              find out what the input was. Key derivation functions extend this
              for use with passwords: bcrypt uses the Blowfish block cipher in
              conjunction with a basic hashing function to generate CPU-hard
              hashes based on salted passwords.
            </aside>
          </section>

          <section>
            <h2><strong>Non-</strong>Cryptographic hash function</h2>
            <aside class="notes">
              <p>
                Not all hash functions have to be cryptographic, though.
                There's also a place for functions that are fast and reasonably
                well distributed, but provide no guarantee of security. Some
                can also minimise memory usage.
              </p>
              <p>
                This is the world of the non-cryptographic hash function.
              </p>
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>Why?</h1>
          </section>

          <section>
            <h2>Hash tables</h2>
            <aside class="notes">
              You need some way of distributing things into buckets. Taking a
              hash of the key is usually the easiest way: in this case, you're
              not interested in security, but you are interested in speed.
              (Why would you want to implement a hash table nowadays?)
              <!-- TODO: if time, show a diagram of distribution -->
            </aside>
          </section>

          <section>
            <h2>What have I seen?</h2>
            <aside class="notes">
              Many languages provide set types, but when you're dealing with a
              lot of data you may not want to keep everything in memory.
              Hashing it first can help, particularly if you're doing something
              that can withstand the odd false positive.
            </aside>
          </section>

          <section>
            <h2>Is this valid?</h2>
            <aside class="notes">
              While you'd often need to use a cryptographic hash function for
              checksumming, there are scenarios where you really do just want
              the 2010s version of a parity bit. These can be quick and simple.
            </aside>
          </section>

          <section>
            <h2>Interoperability</h2>
            <aside class="notes">
              People spec weird things all the time. New Relic CAT example.
            </aside>
          </section>

          <section>
            <h2>It's fun?</h2>
          </section>
        </section>

        <section>
          <section>
            <h1>How?</h1>
          </section>

          <section>
            <h2>Goals</h2>
            <ul>
              <li>Fast</li>
              <li>Well distributed output</li>
            </ul>
            <aside class="notes">
              <p>
                There are two key goals. We want something that's quick, and we
                want something that distributes its output well. A common use
                of non-cryptographic hash functions is in implementing hash
                tables &mdash; while that's not usually a huge concern in
                Python, you don't want clumps in your output, because that
                often leads to collisions.
              </p>
            </aside>
          </section>

          <section>
            <h2>Avalanche effect</h2>
            <div class="input">
              <div><code>000<strong>10</strong>000</code></div>
              <div><code>000<strong>01</strong>000</code></div>
              <div><code>000<strong>11</strong>000</code></div>
              <div><code>000<strong>00</strong>000</code></div>
            </div>
            <div style="font-size: 2em">
              <span class="octicon mega-octicon octicon-arrow-down"></span>
            </div>
            <div class="output">
              <code>000<strong>??</strong>00</code>
            </div>
            <aside class="notes">
              This is what you don't want. You want each change to the data to
              have a bigger effect on the output.
            </aside>
          </section>

          <section>
            <h2>Avalanche effect</h2>
            <div class="input">
              <div><code>000<strong>10</strong>000</code></div>
              <div><code>000<strong>01</strong>000</code></div>
              <div><code>000<strong>11</strong>000</code></div>
              <div><code>000<strong>00</strong>000</code></div>
            </div>
            <div style="font-size: 2em">
              <span class="octicon mega-octicon octicon-arrow-down"></span>
            </div>
            <div class="output">
              <code><strong>????????</strong></code>
            </div>
            <aside class="notes">
              Having each change have a large change on the output is called
              the avalanche effect.
            </aside>
          </section>

          <section>
            <pre><code class="python" data-trim>
def hash_function(data: bytes) -&gt; int:
  for chunk in md_pad(data):
    hash = cleverness(hash, chunk)

  return hash
            </code></pre>
            <aside class="notes">
              <p>
                Broadly, this is how every hash function is constructed. Easy,
                huh? (Python provides a cleverness function, I'm sure.)
                Cleverness is actually a "mixing function": it takes the
                current state and mutates it with the chunk.
              </p>
              <p>
                Chunk sizes vary, but are most commonly bytes or 32-bit words.
              </p>
              <p>
                As an aside, cryptographic hash functions usually use a
                Merkle-Damgård (DAM-gour(d)) construction, which adds padding
                in a specific way, but is otherwise a fancy (and hard) way of
                saying this.
              </p>
            </aside>
          </section>

          <section>
            <h2>Cleverness</h2>
            <ul>
              <li>Unsigned, fixed length integers</li>
              <li>Bitwise operations (<code>xor</code>; bitshifts)</li>
              <li>Multiplication</li>
              <li>Primes</li>
            </ul>
            <aside class="notes">
              The basic constructs that tend to be used. Bitshifts and xor are
              extremely useful when the input has little variance, as they can
              be used to force lots of changes to otherwise unaffected bits.
            </aside>
          </section>

          <section>
            <h2>Integers</h2>
            <pre><code>  0xffffffff
+ 0x00000001
= 0x00000000</code></pre>
            <aside class="notes">
              Integer overflow behaviour is used heavily. In higher level
              languages like Python, you may have issues with the integer type
              being unlimited precision, but most of this kind of work is
              usually done in C anyway.
            </aside>
          </section>

          <section>
            <h2>Primes</h2>
            <aside class="notes">
              Most hashing algorithms include one or more (usually more) prime
              numbers as constants. This is mostly for bucketing behaviour: if
              you're using the output to place things into buckets, you don't
              want common factors lest you end up bucketing naïvely into the
              same buckets &mdash; if your hash function is biased towards
              multiples of eight and you're implementing something with eight
              buckets, you may not end up using seven of them much.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>FNV-1a</h1>
            <aside class="notes">
              Let's walk slowly through an example: in this case, FNV-1a. FNV
              was created by Glenn Fowler, Landon Curt Noll and Phong Vo in
              1991, and later revised to improve its avalanche behaviour. It's
              still widely used today, and is simple enough that we can step
              through it and see the principles noted above in action.
            </aside>
          </section>

          <section>
            <h2>FNV-1a</h2>
            <pre><code class="c" data-trim>
uint32_t fnv1a32(char *data, size_t len) {
  uint32_t hash = 2166136261;
  for (char *byte = data; byte < (data + len); byte++) {
    hash ^= *byte;
    hash *= 16777619;
  }
  return hash;
}
            </code></pre>
            <aside class="notes">
              Here's the C implementation of the algorithm.  Conceptually, it's
              very simple: for each byte (since it's a bytewise algorithm), we
              xor the hash value, then multiply it. Note that we'll see lots of
              magic numbers.
            </aside>
          </section>

          <!--
          <section>
            <h2>FNV-1a</h2>
            <svg class="flowchart" width="1000" height="500">
              <defs>
                <marker id="arrowhead" markerWidth="6" markerHeight="6" orient="auto" refX="6" refY="3">
                  <path d="M0,0 L6,3 0,6" />
                </marker>
              </defs>

              <rect class="terminal" x="5" y="210" height="80" width="150" rx="20" ry="20" />
              <text class="label" x="80" y="250">data</text>

              <rect class="terminal" x="845" y="210" height="80" width="150" rx="20" ry="20" />
              <text class="label" x="920" y="250">hash</text>

              <rect class="action xor" x="370" y="210" height="80" width="80" />
              <text class="label" x="410" y="250">^</text>

              <rect class="action mult" x="550" y="210" height="80" width="80" />
              <text class="label" x="590" y="250">*</text>

              <line class="arrow" x1="155" y1="250" x2="370" y2="250" />
              <line class="arrow" x1="450" y1="250" x2="550" y2="250" />
              <line class="arrow" x1="630" y1="250" x2="845" y2="250" />
              <path class="arrow" d="M590 290 V 340 C 590 440, 410 440, 410 340 V 290" />
            </svg>
          </section>
          -->

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
&gt;   uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1000 0001 0001 1100 1001 1101 1100 0101</pre></code>
            <code><pre>*byte: (unset)</pre></code>
            <aside class="notes">
              First, we set our hash value to a randomly selected number. This
              isn't actually a prime: it's not chosen for its dispersal
              characteristics, but rather is simply a non-zero value so that
              the initial hash value isn't all zeroes. (In fact, it's the FNV-0
              hash of the e-mail signature line of Landon Curt Noll!)
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
&gt;   for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1000 0001 0001 1100 1001 1101 1100 0101</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Pick a byte (lowercase "a").
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
&gt;     hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1000 0001 0001 1100 1001 1101 1<strong>01</strong>0 010<strong>0</strong></pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Now we do the exclusive-or. Note that only three bits in hash
              actually changed. Not very avalanchey!
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
&gt;     hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1<strong>11</strong>0 0<strong>1</strong>0<strong>0</strong> 000<strong>0</strong> 1100 <strong>0</strong>0<strong>10</strong> 1<strong>0</strong>01 <strong>001</strong>0 <strong>1</strong>100</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Now we see some changes! The sharp of eye would have noticed that
              this prime is close to 2^24, which means that we're effectively
              performing a bitshift with some added noise in the lower bits.
              There's some avalanche.
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
&gt;   for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1110 0100 0000 1100 0010 1001 0010 1100</pre></code>
            <code><pre>*byte:                               0110 00<strong>10</strong></pre></code>
            <aside class="notes">
              Now we do it again with b, which is only two bits different from
              a.
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
&gt;     hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1110 0100 0000 1100 0010 1001 0<strong>10</strong>0 11<strong>1</strong>0</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Again, only three bits change when we do the xor.
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
&gt;     hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  <strong>0</strong>1<strong>0</strong>0 <strong>1</strong>10<strong>1</strong> 00<strong>1</strong>0 <strong>0</strong>10<strong>1</strong> 00<strong>0</strong>0 <strong>01</strong>01 <strong>1</strong>100 1<strong>0</strong>10</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              You can see how well distributed the changes are, even after only
              two bytes of input. Every nibble has one or two bits modified. A
              small change resulted in a big change.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>Shootout</h1>
            <aside class="notes">
              Let's look at a few functions (specifically, the 32 bit versions
              where appropriate). I've chosen functions that are feasible to
              implement in a variety of languages (so don't rely on anything in
              particular) and are generally considered to be among the state of
              the art. Firstly, though, we need a way to compare them.
            </aside>
          </section>

          <section>
            <h2>Goals</h2>
            <ul>
              <li>Fast</li>
              <li>Well distributed output</li>
            </ul>
            <aside class="notes">
              Let's look at our goals again. How can we judge them?
            </aside>
          </section>

          <section>
            <h2>Fast</h2>
            <aside class="notes">
              Fast is easy. CPU time pretty much tells us that.
            </aside>
          </section>

          <section>
            <h2>Distribution</h2>
            <aside class="notes">
              We can look at collisions. So let's talk about inputs.
            </aside>
          </section>

          <section>
            <h2>Input: words</h2>
            <pre><code class="nohighlight" data-trim>
A
a
aa
aal
aalii
aam
Aani
aardvark
            </code></pre>
            <aside class="notes">
              This is the OS X /usr/share/dict/words. This is a good test for
              collisions, and an interesting one for performance with lots of
              varied, short inputs.
            </aside>
          </section>

          <section>
            <h2>Input: numbers</h2>
            <pre><code class="nohighlight" data-trim>
0
1
2
3
4
5
6
7
            </code></pre>
            <aside class="notes">
              This is a file of numbers from 0 to 235885 (the same size as the
              words input). Again, this is really interesting for collisions: a
              less varied input.
            </aside>
          </section>

          <section>
            <h2>Input: Holmes</h2>
            <img src="images/Holmes_by_Paget.jpg">
            <aside class="notes">
              The complete Sherlock Holmes canon, with each adventure or novel
              as a separate input. This is a good performance test for larger
              (40k-200k) inputs. (Less likely for hashtable keys, but likely
              for "have I seen this" cases.)
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>FNV-1a</h1>
            <aside class="notes">
              Since we've already looked at FNV-1a in some detail, let's look
              at some results for it.
            </aside>
          </section>

          <section>
            <h2>FNV-1a</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>55.40</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>68.12</td>
                  <td>5 (0.002%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>3.13</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              There are collisions in the word corpus. This isn't really
              unexpected: we're only getting 32 bit values, and given the
              birthday paradox, there's a greater than 75% chance of a
              collision for a naïve hash function with more than 200000 inputs.
            </aside>
          </section>

          <section>
            <h2>FNV-1a</h2>
            <img src="images/fnv1a32.png">
            <aside class="notes">
              <p>
                Another way to visualise the distribution besides just the
                number of collisions is to map it out. I've shamelessly stolen
                this approach from Ian Boyd, who wrote a seminal StackExchange
                essay on hashing functions three years ago.
              </p>
              <p>
                White dots indicate unused values within the output.
              </p>
              <p>
                Basically, you want this to look like noise. FNV-1a is pretty
                good on this count.
              </p>
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>CRC32</h1>
            <aside class="notes">
              Another classic algorithm is CRC32, which dates from 1961. It's
              another byte-wise algorithm.
            </aside>
          </section>

          <section>
            <h2>CRC32</h2>
            <pre><code class="c" data-trim>
static const unsigned int crc32tab[256] = { /* ... */ };

uint32_t crc32(const char *data, size_t len) {
  uint32_t crc = 0;
  const char *ptr;

  for (ptr = data; ptr < (data + len); ptr++) {
    crc = ((crc &gt;&gt; 8) &amp; 0x00ffffff) ^
          crc32tab[(crc ^ (*ptr)) &amp; 0xff];
  }

  return crc;
}
            </code></pre>
            <aside class="notes">
              CRC is interesting because it uses very basic primitives, but
              combines them with a lookup table that is used for extra mixing.
            </aside>
          </section>

          <!--
          <section>
            <h2>CRC32</h2>
            <svg class="flowchart" width="1000" height="500">
              <defs>
                <marker id="arrowhead" markerWidth="6" markerHeight="6" orient="auto" refX="6" refY="3">
                  <path d="M0,0 L6,3 0,6" />
                </marker>
              </defs>

              <rect class="terminal" x="5" y="210" height="80" width="150" rx="20" ry="20" />
              <text class="label" x="80" y="250">data</text>

              <rect class="terminal" x="845" y="210" height="80" width="150" rx="20" ry="20" />
              <text class="label" x="920" y="250">hash</text>

              <rect class="terminal" x="540" y="60" height="80" width="180" rx="20" ry="20" />
              <text class="label" x="630" y="100">table</text>

              <rect class="action shift" x="330" y="210" height="80" width="80" />
              <text class="label" x="370" y="250">&lt;&lt;</text>

              <rect class="action and" x="460" y="210" height="80" width="80" />
              <text class="label" x="500" y="250">&amp;</text>

              <rect class="action xor" x="590" y="210" height="80" width="80" />
              <text class="label" x="630" y="250">^</text>

              <line class="arrow" x1="155" y1="250" x2="330" y2="250" />
              <line class="arrow" x1="410" y1="250" x2="460" y2="250" />
              <line class="arrow" x1="540" y1="250" x2="590" y2="250" />
              <line class="arrow" x1="670" y1="250" x2="845" y2="250" />
              <line class="arrow" x1="630" y1="140" x2="630" y2="210" />
              <path class="arrow" d="M630 290 V 340 C 630 440, 370 440, 370 340 V 290" />
            </svg>
          </section>
          -->

          <section>
            <h2>CRC32</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>% FNV-1a</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>70.69</td>
                  <td>128%</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>80.23</td>
                  <td>118%</td>
                  <td>8 (0.003%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>6.70</td>
                  <td>214%</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              It's a bit slower than FNV-1a, but it's still pretty good for a
              byte-wise algorithm.
            </aside>
          </section>

          <section>
            <h2>CRC32</h2>
            <img src="images/crc32.png">
            <aside class="notes">
              You can see some clumping in here. This is because of the lookup
              table: values will tend towards certain buckets.
            </aside>
          </section>
        </section>

        <section>
          <section id="mm3-title">
            <h1>MurmurHash3</h1>
            <aside class="notes">
              MurmurHash3 is another relatively simple to implement hashing
              function. As the name implies, it's the third revision of a
              function designed by Austin Appleby. The name is inspired by two
              basic operations: MUltiply and Rotate.
            </aside>
          </section>

          <section id="mm3">
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim style="font-size: 0.32em">
uint32_t murmurhash3_32(const char *data, size_t len, uint32_t seed) {
  static const uint32_t c1 = 0xcc9e2d51;
  static const uint32_t c2 = 0x1b873593;
  static const uint32_t r1 = 15;
  static const uint32_t r2 = 13;
  static const uint32_t m = 5;
  static const uint32_t n = 0xe6546b64;

  uint32_t hash = seed;

  const int nblocks = len / 4;
  const uint32_t *blocks = (const uint32_t *) data;
  for (int i = 0; i < nblocks; i++) {
    uint32_t k = blocks[i];
    k *= c1;
    k = (k &lt;&lt; r1) | (k &gt;&gt; (32 - r1));
    k *= c2;

    hash ^= k;
    hash = ((hash &lt;&lt; r2) | (hash &gt;&gt; (32 - r2))) * m + n;
  }

  const uint8_t *tail = (const uint8_t *) (data + nblocks * 4);
  uint32_t k1 = 0;

  switch (len &amp; 3) {
  case 3:
    k1 ^= tail[2] &lt;&lt; 16;
  case 2:
    k1 ^= tail[1] &lt;&lt; 8;
  case 1:
    k1 ^= tail[0];

    k1 *= c1;
    k1 = (k1 &lt;&lt; r1) | (k1 &gt;&gt; (32 - r1));
    k1 *= c2;
    hash ^= k1;
  }

  hash ^= len;
  hash ^= (hash &gt;&gt; 16);
  hash *= 0x85ebca6b;
  hash ^= (hash &gt;&gt; 13);
  hash *= 0xc2b2ae35;
  hash ^= (hash &gt;&gt; 16);

  return hash;
}
            </code></pre>
            <aside class="notes">
              Yikes! It's not that bad, though. Let's break it down: this is
              typical of a more modern hash function.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
uint32_t murmurhash3_32(const char *data,
                        size_t      len,
                        uint32_t    seed);
            </code></pre>
            <aside class="notes">
              Here's the prototype. A lot of modern hash functions are
              initialised with seeds. This makes it harder to construct DoS
              attacks: if the caller can use a random number to seed, you can't
              pre-compute what will collide.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
static const uint32_t c1 = 0xcc9e2d51;
static const uint32_t c2 = 0x1b873593;
static const uint32_t r1 = 15;
static const uint32_t r2 = 13;
static const uint32_t m = 5;
static const uint32_t n = 0xe6546b64;

uint32_t hash = seed;
            </code></pre>
            <aside class="notes">
              We define a bunch of constants, and set up the initial hash value
              from the seed.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
const size_t nblocks = len / 4;
const uint32_t *blocks = (const uint32_t *) data;

for (size_t i = 0; i < nblocks; i++) {
  uint32_t k = blocks[i];

  k *= c1;
  k = (k &lt;&lt; r1) | (k &gt;&gt; (32 - r1));
  k *= c2;

  hash ^= k;
  hash = ((hash &lt;&lt; r2) | (hash &gt;&gt; (32 - r2))) * m + n;
}
            </code></pre>
            <aside class="notes">
              Here's the heart of the mixing function. Note use of four bytes
              at a time instead of one (no unaligned access, cache friendly),
              use of C reinterpret casting semantics, and same math primitives.
              Trailing bytes are left off by nblocks integer division. Note
              constants; n is pretty close to 2^32 (enforce overflow).
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
const uint8_t *tail;
tail = (const uint8_t *) (data + nblocks * 4);
            </code></pre>
            <aside class="notes">
              Go through some gymnastics for the last few bytes to ensure
              they're properly mixed into the hash value. Note that we're
              interpreting the tail as bytes, rather than words.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim style="font-size: 1.1em">
uint32_t k1 = 0;
switch (len &amp; 3) {
  case 3:
    k1 ^= tail[2] &lt;&lt; 16;
  case 2:
    k1 ^= tail[1] &lt;&lt; 8;
  case 1:
    k1 ^= tail[0];

    k1 *= c1;
    k1 = (k1 &lt;&lt; r1) | (k1 &gt;&gt; (32 - r1));
    k1 *= c2;
    hash ^= k1;
}
            </code></pre>
            <aside class="notes">
              The use of a different mixing function for the last few bytes is
              common. Each byte gets mixed into k1, then additional mixing
              takes place before it's mixed into the main hash.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
hash ^= len;
hash ^= (hash &gt;&gt; 16);
hash *= 0x85ebca6b;
hash ^= (hash &gt;&gt; 13);
hash *= 0xc2b2ae35;
hash ^= (hash &gt;&gt; 16);

return hash;
            </code></pre>
            <aside class="notes">
              Finally, after all mixing, some postprocessing occurs. This is
              common in newer hash functions: with careful chosen values, you
              can attempt to invoke additional avalanching, but this can also
              be a source of weakness (clumping).
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>% FNV-1a</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>69.10</td>
                  <td>125%</td>
                  <td>4 (0.002%)</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>69.23</td>
                  <td>102%</td>
                  <td>6 (0.003%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>0.95</td>
                  <td>30%</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              A few more collisions, which is unfortunate. It's slower for
              small inputs than FNV-1a (which isn't surprising, given the extra
              setup work), but way faster for larger inputs because it's
              word-wise.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <img src="images/murmurhash3.png">
          </section>
        </section>

        <section>
          <section>
            <h1>xxHash</h1>
            <aside class="notes">
              xxHash is another relatively new hash function that has been
              quickly adopted by a number of projects, including pfSense and
              TeamViewer. (For what, I don't know.) It has a similar
              construction to MurmurHash3, except it reads 16 bytes at a time.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 0.25em">
const uint32_t xxhash32_prime1 = 2654435761U;
const uint32_t xxhash32_prime2 = 2246822519U;
const uint32_t xxhash32_prime3 = 3266489917U;
const uint32_t xxhash32_prime4 = 668265263U;
const uint32_t xxhash32_prime5 = 374761393U;

inline uint32_t xxhash32_rotl(uint32_t x, int r) {
  return (x &lt;&lt; r) | (x &gt;&gt; (32 - r));
}

inline uint32_t xxhash32_mix(uint32_t v, uint32_t chunk) {
  v += chunk * xxhash32_prime2;
  v = xxhash32_rotl(v, 13);
  return v * xxhash32_prime1;
}

uint32_t xxhash32(const char *data, size_t len, uint32_t seed) {
  const char *p = data;
  const char *end = data + len;

  uint32_t hash = 0;

  if (len &gt;= 16) {
    uint32_t v1 = seed + xxhash32_prime1 + xxhash32_prime2;
    uint32_t v2 = seed + xxhash32_prime2;
    uint32_t v3 = seed;
    uint32_t v4 = seed - xxhash32_prime1;

    for (; p &lt;= (end - 16); p += 16) {
      const uint32_t *chunk = (const uint32_t *) p;

      v1 = xxhash32_mix(v1, chunk[0]);
      v2 = xxhash32_mix(v2, chunk[1]);
      v3 = xxhash32_mix(v3, chunk[2]);
      v4 = xxhash32_mix(v4, chunk[3]);
    }

    hash = xxhash32_rotl(v1, 1) +
           xxhash32_rotl(v2, 7) +
           xxhash32_rotl(v3, 12) +
           xxhash32_rotl(v4, 18);
  } else {
    hash = seed + xxhash32_prime5;
  }

  for (; (p + 4) &lt;= end; p += 4) {
    hash += *((const uint32_t *) p) * xxhash32_prime3;
    hash = xxhash32_rotl(hash, 17) * xxhash32_prime4;
  }

  for (; p &lt; end; p++) {
    hash += ((uint8_t) *p) * xxhash32_prime5;
    hash = xxhash32_rotl(hash, 11) * xxhash32_prime1;
  }

  hash ^= hash &gt;&gt; 15;
  hash *= xxhash32_prime2;
  hash ^= hash &gt;&gt; 13;
  hash *= xxhash32_prime3;
  hash ^= hash &gt;&gt; 16;

  return hash;
}
            </code></pre>
            <aside class="notes">
              This one's even bigger &mdash; probably as big as you'd really
              ever want to implement &mdash; but the principle is the same.
              (This is simplified.) Some primes are defined atop, some utility
              functions are defined, and then there are three mixing functions:
              one for when you can read 16 bytes, one for 4 bytes, and one for
              1 byte.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
uint32_t v1 = seed + xxhash32_prime1 + xxhash32_prime2;
uint32_t v2 = seed + xxhash32_prime2;
uint32_t v3 = seed;
uint32_t v4 = seed - xxhash32_prime1;
            </code></pre>
            <aside class="notes">
              The 16 byte case starts by using the seed and two of the five
              primes to set up four working variables.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
for (; p &lt;= (end - 16); p += 16) {
  const uint32_t *chunk = (const uint32_t *) p;

  v1 = xxhash32_mix(v1, chunk[0]);
  v2 = xxhash32_mix(v2, chunk[1]);
  v3 = xxhash32_mix(v3, chunk[2]);
  v4 = xxhash32_mix(v4, chunk[3]);
}
            </code></pre>
            <aside class="notes">
              Then it reads 16 bytes at a time and mixes each 4 byte chunk into
              those working variables.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
inline uint32_t xxhash32_rotl(uint32_t x, int r) {
  return (x &lt;&lt; r) | (x &gt;&gt; (32 - r));
}

inline uint32_t xxhash32_mix(uint32_t v, uint32_t in) {
  v += in * xxhash32_prime2;
  v = xxhash32_rotl(v, 13);
  return v * xxhash32_prime1;
}
            </code></pre>
            <aside class="notes">
              The mixing function itself is very similar to MurmurHash3:
              multiply by a prime, rotate, and multiply again.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
hash = xxhash32_rotl(v1, 1) +
       xxhash32_rotl(v2, 7) +
       xxhash32_rotl(v3, 12) +
       xxhash32_rotl(v4, 18);
            </code></pre>
            <aside class="notes">
              Finally, we set the hash, then move onto the 4 byte case to
              handle trailing data.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
if (len &gt;= 16) {
  /* what you just saw */
} else {
  hash = seed + xxhash32_prime5;
}
            </code></pre>
            <aside class="notes">
              There's a separate initialisation case for small inputs.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
for (; (p + 4) &lt;= end; p += 4) {
  hash += *((const uint32_t *) p) * xxhash32_prime3;
  hash = xxhash32_rotl(hash, 17) * xxhash32_prime4;
}

for (; p &lt; end; p++) {
  hash += ((uint8_t) *p) * xxhash32_prime5;
  hash = xxhash32_rotl(hash, 11) * xxhash32_prime1;
}
            </code></pre>
            <aside class="notes">
              There are then the 4 and 1 byte mixers, which are used until all
              the data has been mixed.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="python" data-trim style="font-size: 1.3em">
hash ^= hash &gt;&gt; 15;
hash *= xxhash32_prime2;
hash ^= hash &gt;&gt; 13;
hash *= xxhash32_prime3;
hash ^= hash &gt;&gt; 16;

return hash;
            </code></pre>
            <aside class="notes">
              Finally, a post processing step. Notice how these all look pretty
              similar now you know how to break them down?
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>% FNV-1a</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>69.41</td>
                  <td>125%</td>
                  <td>2 (0.001%)</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>73.97</td>
                  <td>109%</td>
                  <td>6 (0.003%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>0.396</td>
                  <td>12.6%</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              Minimal collisions, slightly slower than MurmurHash3 on small
              inputs, but even quicker on fast because of the hoops it jumps
              through for speed (reading 16 bytes at a time).
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <img src="images/xxhash32.png">
          </section>
        </section>

        <section>
          <section>
            <h1 style="font-size: 2.5em">SuperFastHash</h1>
            <aside class="notes">
              All these good hash functions are boring. Let's look at what
              happens when you use a bad function. To quote NonCryptoHashZoo:
              SuperFastHash is the quintessential example of how easy it is to
              go wrong when making your own hash function even if you're
              incredibly smart.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="c" data-trim style="font-size: 0.3em">
inline uint16_t get16bits(const char *p) {
  return *(const uint16_t*)p;
}

uint32_t superfasthash(const char *data, size_t len) {
  uint32_t hash = 0;
  uint32_t tmp;
  size_t rem;

  rem = len &amp; 3;
  len &gt;&gt;= 2;

  for (; len &gt; 0; len--) {
    hash  += get16bits (data);
    tmp    = (get16bits (data+2) &lt;&lt; 11) ^ hash;
    hash   = (hash &lt;&lt; 16) ^ tmp;
    data  += 2*sizeof (uint16_t);
    hash  += hash &gt;&gt; 11;
  }

  switch (rem) {
    case 3:	hash += get16bits (data);
        hash ^= hash &lt;&lt; 16;
        hash ^= data[sizeof (uint16_t)] &lt;&lt; 18;
        hash += hash &gt;&gt; 11;
        break;
    case 2:	hash += get16bits (data);
        hash ^= hash &lt;&lt; 11;
        hash += hash &gt;&gt; 17;
        break;
    case 1: hash += *data;
        hash ^= hash &lt;&lt; 10;
        hash += hash &gt;&gt; 1;
  }

  hash ^= hash &lt;&lt; 3;
  hash += hash &gt;&gt; 5;
  hash ^= hash &lt;&lt; 4;
  hash += hash &gt;&gt; 17;
  hash ^= hash &lt;&lt; 25;
  hash += hash &gt;&gt; 6;

  return hash;
}
            </code></pre>
            <aside class="notes">
              Interesting: there's no initial state besides the seed and the
              length of the input.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
for (; len &gt; 0; len--) {
  hash  += get16bits(data);
  tmp    = (get16bits(data + 2) &lt;&lt; 11) ^ hash;
  hash   = (hash &lt;&lt; 16) ^ tmp;
  data  += 2 * sizeof(uint16_t);
  hash  += hash &gt;&gt; 11;
}
            </code></pre>
            <aside class="notes">
              This is the main mixing function. It deals in four byte chunks,
              but actually handles the high and low 16 bits separately. There
              are some gymnastics around bitshifting, but note that shift
              amounts are the same.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="c" data-trim style="font-size: 1em">
if (rem == 3) {
  hash += get16bits(data);
  hash ^= hash &lt;&lt; 16;
  hash ^= data[sizeof(uint16_t)] &lt;&lt; 18;
  hash += hash &gt;&gt; 11;
} else if (rem == 2) {
  hash += get16bits(data);
  hash ^= hash &lt;&lt; 11;
  hash += hash &gt;&gt; 17;
} else if (rem == 1) {
  hash += *data;
  hash ^= hash &lt;&lt; 10;
  hash += hash &gt;&gt; 1;
}
            </code></pre>
            <aside class="notes">
              Trailing bytes are handled differently based on the size, which
              is interesting.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="c" data-trim style="font-size: 1.3em">
hash ^= hash &lt;&lt; 3;
hash += hash &gt;&gt; 5;
hash ^= hash &lt;&lt; 4;
hash += hash &gt;&gt; 17;
hash ^= hash &lt;&lt; 25;
hash += hash &gt;&gt; 6;

return hash;
            </code></pre>
            <aside class="notes">
              Probably because of the similar bitshifts, there's a lot of
              shifting in the post processing. The problem is that the damage
              has been done by now: the 4 byte loop often collapses into the
              same state, and then you're going to end up with basically the
              same output.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>% FNV-1a</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>66.13</td>
                  <td>119%</td>
                  <td>23946 (10.152%)</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>82.01</td>
                  <td>120%</td>
                  <td>54 (0.023%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>9.68</td>
                  <td>310%</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              Oh. Oh dear. Hell, it's even slower than FNV-1a, so you're not
              even trading speed for distribution.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <img src="images/superfasthash.png">
            <aside class="notes">
              See that stripe down the right hand side? That's not good. That's
              a lot of values collapsing into the same buckets.
            </aside>
          </section>

          <section>
            <h2>JSHash</h2>
            <img src="images/jshash.png">
            <aside class="notes">
              Of course, it could be worse. I won't go through the
              implementation of this one, but this is the output of JSHash
              (Justin Sobel) with the numbers input. We used this in a bog
              standard chained hash table implementation, and then switched to
              MurmurHash3 and saw a 0.2% speedup just from that in an unrelated
              project.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1 style="font-size: 3em">Conclusions</h1>
          </section>
          
          <section>
            <h2>Know your environment</h2>
            <aside class="notes">
              MurmurHash3 and xxHash smoke every other algorithm when
              implemented in (OK) C or C++, because they exploit how CPUs
              behave when you're writing at that level. They use cache locality
              and read alignment to their advantage. In Python, though, that's
              just overhead: the byte at a time approach is actually faster
              because of the way the bytes type is implemented, and other
              algorithms can be simpler.
            </aside>
          </section>

          <section>
            <h2>Respect your standard library</h2>
            <aside class="notes">
              If you're working in an interpreted language, chances are
              whatever your language provides in its standard library will be
              written in C and quicker. In Python and PHP, you may as well use
              CRC32, since they're provided. Less work, and faster!
            </aside>
          </section>

          <section>
            <h2>Know your inputs</h2>
            <aside class="notes">
              xxHash makes some compromises that don't make sense if your
              average input is under 16 bytes.
            </aside>
          </section>

          <section data-state="words-chart">
            <h2>Small inputs</h2>
            <canvas id="words-chart" width="1000" height="500"></canvas>
            <aside class="notes">
              For the words corpus, which has a mean size of 9 bytes, the block
              reading algorithms don't do any better. At that point, you might
              as well pick something extremely simple like FNV-1a.
            </aside>
          </section>

          <section data-state="holmes-chart">
            <h2>Large inputs</h2>
            <canvas id="holmes-chart" width="1000" height="500"></canvas>
            <aside class="notes">
              For the Holmes corpus, which has a mean of 67k, the block reading
              algorithms shine. xxHash is crazy fast.
            </aside>
          </section>

          <section>
            <h2>Know your requirements</h2>
            <aside class="notes">
              Understand how many collisions you're willing to bear. The best
              way to figure this out is to implement and test with sample data:
              hash functions are easy to implement, and you can test output
              using sets. You may also want to consider complexity of
              implementation: xxHash is robust, but more complicated.
            </aside>
          </section>
        </section>

        <section>
          <h2>Questions?</h2>
          <a href="https://twitter.com/LGnome">@LGnome</a>
          <h3 style="margin-top: 3em">Resources</h3>
          <ul>
            <li><a href="https://code.google.com/p/smhasher/">SMHasher</a></li>
            <li><a href="http://programmers.stackexchange.com/a/145633">Ian Boyd on StackOverflow</a></li>
          </ul>
        </section>
      </div>

		</div>

		<script src="reveal.js/lib/js/head.min.js"></script>
		<script src="reveal.js/js/reveal.js"></script>
    <script src="js/chart.min.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: false,
				progress: false,
				history: true,
				center: true,
        width: 1280,
        height: 720,

				transition: 'fade', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true }
				]
			});

      Reveal.addEventListener("words-chart", function () {
        new Chart(document.getElementById("words-chart").getContext("2d")).Bar({
          labels: ["FNV-1a", "CRC32", "MurmurHash3", "xxHash"],
          datasets: [
            {
              label: "Words",
              data: [68.12, 80.23, 69.23, 73.97],
            },
          ],
        });
      });

      Reveal.addEventListener("holmes-chart", function () {
        new Chart(document.getElementById("holmes-chart").getContext("2d")).Bar({
          labels: ["FNV-1a", "CRC32", "MurmurHash3", "xxHash"],
          datasets: [
            {
              label: "Holmes",
              data: [3.13, 6.70, 0.95, 0.396],
            },
          ],
        });
      });

		</script>

	</body>
</html>
<!-- vim: set nocin ai et ts=2 sw=2: -->

<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Non-cryptographic hashing</title>

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/fonts.css">
		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="css/sky.css" id="theme">

    <!-- CSS overrides -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet/less" type="text/css" href="less/animate.less">
    <link rel="stylesheet/less" type="text/css" href="less/flowchart.less">

    <script src="less.min.js"></script>

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="reveal.js/lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<div class="slides">
				<section class="title">
          <h1>Non-cryptographic hashing</h1>
          <h3>
            Adam Harvey
            <br>
            <a href="https://twitter.com/LGnome">@LGnome</a>
            <br>
            <a href="http://newrelic.com">New Relic</a>
          </h3>
				</section>

        <section>
          <section>
            <h1>What?</h1>
          </section>

          <section>
            <h2>Hash function</h2>
            <aside class="notes">
              Let's start with the obvious: what is a hash function? (Most of
              you likely know this already, but let's make sure we're all on
              the same page.
            </aside>
          </section>

          <section class="input-output">
            <div class="input scroll-4">
              <div>
                <code>Lorem ipsum dolor sit amet,</code>
                <code>consectetur adipiscing elit.</code>
                <code>Integer vitae ex nec nisl</code>
                <code>fermentum sodales in ut lectus.</code>
              </div>
            </div>
            <div style="font-size: 2em">
              <span class="octicon mega-octicon octicon-arrow-down"></span>
            </div>
            <div class="output cycle-4">
              <code>61df8894</code>
              <code>0ec572f8</code>
              <code>19e37640</code>
              <code>372ecf1b</code>
            </div>
            <aside class="notes">
              Fundamentally, a hash function takes any amount of data and
              returns a number based on that data.
            </aside>
          </section>

          <section>
            <h2 id="hash-functions">
              <code>MD5</code>
              <code>SHA-1</code>
              <code>SHA-256</code>
              <code>SHA-512</code>
            </h2>
            <aside class="notes">
              We use them every day. They underpin SSL, block encryption,
              password storage, and many other things that we take for granted.
            </aside>
          </section>

          <section>
            <h2><strong style="opacity: 0">Non-</strong>Cryptographic hash function</h2>
            <aside class="notes">
              All of those are cryptographic hash functions, though. They're
              designed with specific qualities in mind: to make it as difficult
              as possible to generate collisions and to be able to work back to
              find out what the input was. Key derivation functions extend this
              for use with passwords: bcrypt uses the Blowfish block cipher in
              conjunction with a basic hashing function to generate CPU-hard
              hashes based on salted passwords.
            </aside>
          </section>

          <section>
            <h2><strong>Non-</strong>Cryptographic hash function</h2>
            <aside class="notes">
              <p>
                Not all hash functions have to be cryptographic, though.
                There's also a place for functions that are fast and reasonably
                well distributed, but provide no guarantee of security. Some
                can also minimise memory usage.
              </p>
              <p>
                This is the world of the non-cryptographic hash function.
              </p>
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>Why?</h1>
          </section>

          <section>
            <h2>Hash tables</h2>
            <aside class="notes">
              You need some way of distributing things into buckets. Taking a
              hash of the key is usually the easiest way: in this case, you're
              not interested in security, but you are interested in speed.
              (Why would you want to implement a hash table nowadays?)
              <!-- TODO: if time, show a diagram of distribution -->
            </aside>
          </section>

          <section>
            <h2>What have I seen?</h2>
            <aside class="notes">
              Many languages provide set types, but when you're dealing with a
              lot of data you may not want to keep everything in memory.
              Hashing it first can help, particularly if you're doing something
              that can withstand the odd false positive.
            </aside>
          </section>

          <section>
            <h2>Is this valid?</h2>
            <aside class="notes">
              While you'd often need to use a cryptographic hash function for
              checksumming, there are scenarios where you really do just want
              the 2010s version of a parity bit. These can be quick and simple.
            </aside>
          </section>

          <section>
            <h2>Interoperability</h2>
            <aside class="notes">
              People spec weird things all the time. New Relic CAT example.
            </aside>
          </section>

          <section>
            <h2>It's fun?</h2>
          </section>
        </section>

        <section>
          <section>
            <h1>How?</h1>
          </section>

          <section>
            <h2>Goals</h2>
            <ul>
              <li>Fast</li>
              <li>Well distributed output</li>
            </ul>
            <aside class="notes">
              <p>
                There are two key goals. We want something that's quick, and we
                want something that distributes its output well. A common use
                of non-cryptographic hash functions is in implementing hash
                tables &mdash; while that's not usually a huge concern in
                Python, you don't want clumps in your output, because that
                often leads to collisions.
              </p>
            </aside>
          </section>

          <section>
            <h2>Avalanche effect</h2>
            <div class="input">
              <div><code>000<strong>10</strong>000</code></div>
              <div><code>000<strong>01</strong>000</code></div>
              <div><code>000<strong>11</strong>000</code></div>
              <div><code>000<strong>00</strong>000</code></div>
            </div>
            <div style="font-size: 2em">
              <span class="octicon mega-octicon octicon-arrow-down"></span>
            </div>
            <div class="output">
              <code>000<strong>??</strong>00</code>
            </div>
            <aside class="notes">
              This is what you don't want. You want each change to the data to
              have a bigger effect on the output.
            </aside>
          </section>

          <section>
            <h2>Avalanche effect</h2>
            <div class="input">
              <div><code>000<strong>10</strong>000</code></div>
              <div><code>000<strong>01</strong>000</code></div>
              <div><code>000<strong>11</strong>000</code></div>
              <div><code>000<strong>00</strong>000</code></div>
            </div>
            <div style="font-size: 2em">
              <span class="octicon mega-octicon octicon-arrow-down"></span>
            </div>
            <div class="output">
              <code><strong>????????</strong></code>
            </div>
            <aside class="notes">
              Having each change have a large change on the output is called
              the avalanche effect.
            </aside>
          </section>

          <section>
            <pre><code class="python" data-trim>
def hash_function(data: bytes) -&gt; int:
  for chunk in md_pad(data):
    hash = cleverness(hash, chunk)

  return hash
            </code></pre>
            <aside class="notes">
              <p>
                Broadly, this is how every hash function is constructed. Easy,
                huh? (Python provides a cleverness function, I'm sure.)
                Cleverness is actually a "mixing function": it takes the
                current state and mutates it with the chunk.
              </p>
              <p>
                Chunk sizes vary, but are most commonly bytes or 32-bit words.
              </p>
              <p>
                As an aside, cryptographic hash functions usually use a
                Merkle-Damgård (DAM-gour(d)) construction, which adds padding
                in a specific way, but is otherwise a fancy (and hard) way of
                saying this.
              </p>
            </aside>
          </section>

          <section>
            <h2>Cleverness</h2>
            <ul>
              <li>Unsigned, fixed length integers</li>
              <li>Bitwise operations (<code>xor</code>; bitshifts)</li>
              <li>Multiplication</li>
              <li>Primes</li>
            </ul>
            <aside class="notes">
              The basic constructs that tend to be used. Bitshifts and xor are
              extremely useful when the input has little variance, as they can
              be used to force lots of changes to otherwise unaffected bits.
            </aside>
          </section>

          <section>
            <h2>Integers</h2>
            <pre><code>  0xffffffff
+ 0x00000001
= 0x00000000</code></pre>
            <aside class="notes">
              Integer overflow behaviour is used heavily. In higher level
              languages like Python, you may have issues with the integer type
              being unlimited precision, but most of this kind of work is
              usually done in C anyway.
            </aside>
          </section>

          <section>
            <h2>Primes</h2>
            <aside class="notes">
              Most hashing algorithms include one or more (usually more) prime
              numbers as constants. This is mostly for bucketing behaviour: if
              you're using the output to place things into buckets, you don't
              want common factors lest you end up bucketing naïvely into the
              same buckets &mdash; if your hash function is biased towards
              multiples of eight and you're implementing something with eight
              buckets, you may not end up using seven of them much.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>FNV-1a</h1>
            <aside class="notes">
              Let's walk slowly through an example: in this case, FNV-1a. FNV
              was created by Glenn Fowler, Landon Curt Noll and Phong Vo in
              1991, and later revised to improve its avalanche behaviour. It's
              still widely used today, and is simple enough that we can step
              through it and see the principles noted above in action.
            </aside>
          </section>

          <section>
            <h2>FNV-1a</h2>
            <pre><code class="c" data-trim>
uint32_t fnv1a32(char *data, size_t len) {
  uint32_t hash = 2166136261;
  for (char *byte = data; byte < (data + len); byte++) {
    hash ^= *byte;
    hash *= 16777619;
  }
  return hash;
}
            </code></pre>
            <aside class="notes">
              Here's the C implementation of the algorithm.  Conceptually, it's
              very simple: for each byte (since it's a bytewise algorithm), we
              xor the hash value, then multiply it. Note that we'll see lots of
              magic numbers.
            </aside>
          </section>

          <!--
          <section>
            <h2>FNV-1a</h2>
            <svg class="flowchart" width="1000" height="500">
              <defs>
                <marker id="arrowhead" markerWidth="6" markerHeight="6" orient="auto" refX="6" refY="3">
                  <path d="M0,0 L6,3 0,6" />
                </marker>
              </defs>

              <rect class="terminal" x="5" y="210" height="80" width="150" rx="20" ry="20" />
              <text class="label" x="80" y="250">data</text>

              <rect class="terminal" x="845" y="210" height="80" width="150" rx="20" ry="20" />
              <text class="label" x="920" y="250">hash</text>

              <rect class="action xor" x="370" y="210" height="80" width="80" />
              <text class="label" x="410" y="250">^</text>

              <rect class="action mult" x="550" y="210" height="80" width="80" />
              <text class="label" x="590" y="250">*</text>

              <line class="arrow" x1="155" y1="250" x2="370" y2="250" />
              <line class="arrow" x1="450" y1="250" x2="550" y2="250" />
              <line class="arrow" x1="630" y1="250" x2="845" y2="250" />
              <path class="arrow" d="M590 290 V 340 C 590 440, 410 440, 410 340 V 290" />
            </svg>
          </section>
          -->

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
&gt;   uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1000 0001 0001 1100 1001 1101 1100 0101</pre></code>
            <code><pre>*byte: (unset)</pre></code>
            <aside class="notes">
              First, we set our hash value to a randomly selected number. This
              isn't actually a prime: it's not chosen for its dispersal
              characteristics, but rather is simply a non-zero value so that
              the initial hash value isn't all zeroes. (In fact, it's the FNV-0
              hash of the e-mail signature line of Landon Curt Noll!)
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
&gt;   for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1000 0001 0001 1100 1001 1101 1100 0101</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Pick a byte (lowercase "a").
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
&gt;     hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1000 0001 0001 1100 1001 1101 1<strong>01</strong>0 010<strong>0</strong></pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Now we do the exclusive-or. Note that only three bits in hash
              actually changed. Not very avalanchey!
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
&gt;     hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1<strong>11</strong>0 0<strong>1</strong>0<strong>0</strong> 000<strong>0</strong> 1100 <strong>0</strong>0<strong>10</strong> 1<strong>0</strong>01 <strong>001</strong>0 <strong>1</strong>100</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Now we see some changes! The sharp of eye would have noticed that
              this prime is close to 2^24, which means that we're effectively
              performing a bitshift with some added noise in the lower bits.
              There's some avalanche.
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
&gt;   for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1110 0100 0000 1100 0010 1001 0010 1100</pre></code>
            <code><pre>*byte:                               0110 00<strong>10</strong></pre></code>
            <aside class="notes">
              Now we do it again with b, which is only two bits different from
              a.
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
&gt;     hash ^= *byte;
      hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  1110 0100 0000 1100 0010 1001 0<strong>10</strong>0 11<strong>1</strong>0</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              Again, only three bits change when we do the xor.
            </aside>
          </section>

          <section>
            <h3><code>fnv1a32("ab", 2)</code></h3>
            <pre><code class="c">  uint32_t fnv1a32(char *data, size_t len) {
    uint32_t hash = 2166136261;
    for (char *byte = data; byte < (data + len); byte++) {
      hash ^= *byte;
&gt;     hash *= 16777619;
    }
    return hash;
  }</code></pre>
            <code><pre>hash:  <strong>0</strong>1<strong>0</strong>0 <strong>1</strong>10<strong>1</strong> 00<strong>1</strong>0 <strong>0</strong>10<strong>1</strong> 00<strong>0</strong>0 <strong>01</strong>01 <strong>1</strong>100 1<strong>0</strong>10</pre></code>
            <code><pre>*byte:                               0110 0001</pre></code>
            <aside class="notes">
              You can see how well distributed the changes are, even after only
              two bytes of input. Every nibble has one or two bits modified. A
              small change resulted in a big change.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>Shootout</h1>
            <aside class="notes">
              Let's look at a few functions (specifically, the 32 bit versions
              where appropriate). I've chosen functions that are feasible to
              implement in a variety of languages (so don't rely on anything in
              particular) and are generally considered to be among the state of
              the art. Firstly, though, we need a way to compare them.
            </aside>
          </section>

          <section>
            <h2>Goals</h2>
            <ul>
              <li>Fast</li>
              <li>Well distributed output</li>
            </ul>
            <aside class="notes">
              Let's look at our goals again. How can we judge them?
            </aside>
          </section>

          <section>
            <h2>Fast</h2>
            <aside class="notes">
              Fast is easy. CPU time pretty much tells us that.
            </aside>
          </section>

          <section>
            <h2>Distribution</h2>
            <aside class="notes">
              We can look at collisions. So let's talk about inputs.
            </aside>
          </section>

          <section>
            <h2>Input: words</h2>
            <pre><code class="nohighlight" data-trim>
A
a
aa
aal
aalii
aam
Aani
aardvark
            </code></pre>
            <aside class="notes">
              This is the OS X /usr/share/dict/words. This is a good test for
              collisions, and an interesting one for performance with lots of
              varied, short inputs.
            </aside>
          </section>

          <section>
            <h2>Input: numbers</h2>
            <pre><code class="nohighlight" data-trim>
0
1
2
3
4
5
6
7
            </code></pre>
            <aside class="notes">
              This is a file of numbers from 0 to 235885 (the same size as the
              words input). Again, this is really interesting for collisions: a
              less varied input.
            </aside>
          </section>

          <section>
            <h2>Input: Holmes</h2>
            <img src="images/Holmes_by_Paget.jpg">
            <aside class="notes">
              The complete Sherlock Holmes canon, with each adventure or novel
              as a separate input. This is a good performance test for larger
              (40k-200k) inputs. (Less likely for hashtable keys, but likely
              for "have I seen this" cases.)
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>FNV-1a</h1>
            <aside class="notes">
              Since we've already looked at FNV-1a in some detail, let's look
              at some results for it.
            </aside>
          </section>

          <section>
            <h2>FNV-1a</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>55.40</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>68.12</td>
                  <td>5 (0.002%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>3.13</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              There are collisions in the word corpus. This isn't really
              unexpected: we're only getting 32 bit values, and given the
              birthday paradox, there's a greater than 75% chance of a
              collision for a naïve hash function with more than 200000 inputs.
            </aside>
          </section>

          <section>
            <h2>FNV-1a</h2>
            <img src="images/fnv1a32.png">
            <aside class="notes">
              <p>
                Another way to visualise the distribution besides just the
                number of collisions is to map it out. I've shamelessly stolen
                this approach from Ian Boyd, who wrote a seminal StackExchange
                essay on hashing functions three years ago.
              </p>
              <p>
                White dots indicate unused values within the output.
              </p>
              <p>
                Basically, you want this to look like noise. FNV-1a is pretty
                good on this count.
              </p>
            </aside>
          </section>
        </section>

        <section>
          <section id="mm3-title">
            <h1>MurmurHash3</h1>
            <aside class="notes">
              MurmurHash3 is another relatively simple to implement hashing
              function. As the name implies, it's the third revision of a
              function designed by Austin Appleby. The name is inspired by two
              basic operations: MUltiply and Rotate.
            </aside>
          </section>

          <section id="mm3">
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim style="font-size: 0.32em">
uint32_t murmurhash3_32(const char *data, size_t len, uint32_t seed) {
  static const uint32_t c1 = 0xcc9e2d51;
  static const uint32_t c2 = 0x1b873593;
  static const uint32_t r1 = 15;
  static const uint32_t r2 = 13;
  static const uint32_t m = 5;
  static const uint32_t n = 0xe6546b64;

  uint32_t hash = seed;

  const int nblocks = len / 4;
  const uint32_t *blocks = (const uint32_t *) data;
  for (int i = 0; i < nblocks; i++) {
    uint32_t k = blocks[i];
    k *= c1;
    k = (k &lt;&lt; r1) | (k &gt;&gt; (32 - r1));
    k *= c2;

    hash ^= k;
    hash = ((hash &lt;&lt; r2) | (hash &gt;&gt; (32 - r2))) * m + n;
  }

  const uint8_t *tail = (const uint8_t *) (data + nblocks * 4);
  uint32_t k1 = 0;

  switch (len &amp; 3) {
  case 3:
    k1 ^= tail[2] &lt;&lt; 16;
  case 2:
    k1 ^= tail[1] &lt;&lt; 8;
  case 1:
    k1 ^= tail[0];

    k1 *= c1;
    k1 = (k1 &lt;&lt; r1) | (k1 &gt;&gt; (32 - r1));
    k1 *= c2;
    hash ^= k1;
  }

  hash ^= len;
  hash ^= (hash &gt;&gt; 16);
  hash *= 0x85ebca6b;
  hash ^= (hash &gt;&gt; 13);
  hash *= 0xc2b2ae35;
  hash ^= (hash &gt;&gt; 16);

  return hash;
}
            </code></pre>
            <aside class="notes">
              Yikes! It's not that bad, though. Let's break it down: this is
              typical of a more modern hash function.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
uint32_t murmurhash3_32(const char *data,
                        size_t      len,
                        uint32_t    seed);
            </code></pre>
            <aside class="notes">
              Here's the prototype. A lot of modern hash functions are
              initialised with seeds. This makes it harder to construct DoS
              attacks: if the caller can use a random number to seed, you can't
              pre-compute what will collide.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
static const uint32_t c1 = 0xcc9e2d51;
static const uint32_t c2 = 0x1b873593;
static const uint32_t r1 = 15;
static const uint32_t r2 = 13;
static const uint32_t m = 5;
static const uint32_t n = 0xe6546b64;

uint32_t hash = seed;
            </code></pre>
            <aside class="notes">
              We define a bunch of constants, and set up the initial hash value
              from the seed.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
const size_t nblocks = len / 4;
const uint32_t *blocks = (const uint32_t *) data;

for (size_t i = 0; i < nblocks; i++) {
  uint32_t k = blocks[i];

  k *= c1;
  k = (k &lt;&lt; r1) | (k &gt;&gt; (32 - r1));
  k *= c2;

  hash ^= k;
  hash = ((hash &lt;&lt; r2) | (hash &gt;&gt; (32 - r2))) * m + n;
}
            </code></pre>
            <aside class="notes">
              Here's the heart of the mixing function. Note use of four bytes
              at a time instead of one (no unaligned access, cache friendly),
              use of C reinterpret casting semantics, and same math primitives.
              Trailing bytes are left off by nblocks integer division. Note
              constants; n is pretty close to 2^32 (enforce overflow).
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
const uint8_t *tail;
tail = (const uint8_t *) (data + nblocks * 4);
            </code></pre>
            <aside class="notes">
              Go through some gymnastics for the last few bytes to ensure
              they're properly mixed into the hash value. Note that we're
              interpreting the tail as bytes, rather than words.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim style="font-size: 1.1em">
uint32_t k1 = 0;
switch (len &amp; 3) {
  case 3:
    k1 ^= tail[2] &lt;&lt; 16;
  case 2:
    k1 ^= tail[1] &lt;&lt; 8;
  case 1:
    k1 ^= tail[0];

    k1 *= c1;
    k1 = (k1 &lt;&lt; r1) | (k1 &gt;&gt; (32 - r1));
    k1 *= c2;
    hash ^= k1;
}
            </code></pre>
            <aside class="notes">
              The use of a different mixing function for the last few bytes is
              common. Each byte gets mixed into k1, then additional mixing
              takes place before it's mixed into the main hash.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <pre><code class="c" data-trim>
hash ^= len;
hash ^= (hash &gt;&gt; 16);
hash *= 0x85ebca6b;
hash ^= (hash &gt;&gt; 13);
hash *= 0xc2b2ae35;
hash ^= (hash &gt;&gt; 16);

return hash;
            </code></pre>
            <aside class="notes">
              Finally, after all mixing, some postprocessing occurs. This is
              common in newer hash functions: with careful chosen values, you
              can attempt to invoke additional avalanching, but this can also
              be a source of weakness (clumping).
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (ms)</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>69.10</td>
                  <td>4 (0.002%)</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>69.23</td>
                  <td>6 (0.003%)</td>
                </tr>
                <tr>
                  <td>Holmes</td>
                  <td>0.95</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              A few more collisions, which is unfortunate. Much more
              importantly, though, it's almost three times slower than FNV-1a.
              This is due to CPython being relatively slow, the large number of
              uint32() objects that have to be instantiatied to prevent
              overflow, and the chunking behaviour. In C, though, none of these
              are issues.
            </aside>
          </section>

          <section>
            <h2>MurmurHash3</h2>
            <img src="images/murmurhash3.png">
          </section>
        </section>

        <section>
          <section>
            <h1>xxHash</h1>
            <aside class="notes">
              xxHash is another relatively new hash function that has been
              quickly adopted by a number of projects, including pfSense and
              TeamViewer. (For what, I don't know.) It has a similar
              construction to MurmurHash3, except it reads 16 bytes at a time.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="python" data-trim style="font-size: 0.25em">
def xxhash32(data: bytes, seed: uint32) -> uint32:
    primes = [uint32(n) for n in (
        2654435761,
        2246822519,
        3266489917,
        668265263,
        374761393
    )]

    def rotl(x: uint32, r) -> uint32:
        return (x << uint32(r)) | (x >> uint32(32 - r))

    offset = 0
    def get32bits():
        nonlocal offset

        chunk = data[offset:offset+4]
        offset += 4
        return uint32(unpack("=L", chunk)[0])

    hash = uint32(0)

    if len(data) >= 16:
        v1 = seed + primes[0] + primes[1]
        v2 = seed + primes[1]
        v3 = seed
        v4 = seed - primes[0]

        def mix(v: uint32, chunk: uint32) -> uint32:
            v += chunk * primes[1]
            v = rotl(v, 13)
            return v * primes[0]

        while offset <= (len(data) - 16):
            v1 = mix(v1, get32bits())
            v2 = mix(v2, get32bits())
            v3 = mix(v3, get32bits())
            v4 = mix(v4, get32bits())

        hash = rotl(v1, 1) + rotl(v2, 7) + rotl(v3, 12) + rotl(v4, 18)
    else:
        hash = seed + primes[4]

    hash += uint32(len(data))

    while (offset + 4) < len(data):
        hash += get32bits() * primes[2]
        hash = rotl(hash, 17) * primes[3]

    while offset < len(data):
        hash += uint32(data[offset]) * primes[4]
        offset += 1
        hash = rotl(hash, 11) * primes[0]

    hash ^= hash >> uint32(15)
    hash *= primes[1]
    hash ^= hash >> uint32(13)
    hash *= primes[2]
    hash ^= hash >> uint32(16)

    return hash
            </code></pre>
            <aside class="notes">
              This one's even bigger &mdash; probably as big as you'd really
              ever want to implement &mdash; but the principle is the same.
              Some primes are defined atop, some utility functions are defined,
              and then there are three mixing functions: one for when you can
              read 16 bytes, one for 4 bytes, and one for 1 byte.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="python" data-trim style="font-size: 1.3em">
def mix(v: uint32, chunk: uint32) -> uint32:
    v += chunk * primes[1]
    v = rotl(v, 13)
    return v * primes[0]

while offset <= (len(data) - 16):
    v1 = mix(v1, get32bits())
    v2 = mix(v2, get32bits())
    v3 = mix(v3, get32bits())
    v4 = mix(v4, get32bits())

hash = rotl(v1, 1) + rotl(v2, 7) +
       rotl(v3, 12) + rotl(v4, 18)
            </code></pre>
            <aside class="notes">
              Here's the 16 byte mixing function. Note that it keeps four
              running values and combines them at the end.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="python" data-trim style="font-size: 1.3em">
while (offset + 4) < len(data):
    hash += get32bits() * primes[2]
    hash = rotl(hash, 17) * primes[3]

while offset < len(data):
    hash += uint32(data[offset]) * primes[4]
    offset += 1
    hash = rotl(hash, 11) * primes[0]
            </code></pre>
            <aside class="notes">
              There are then the 4 and 1 byte mixers, which are used until all
              the data has been mixed.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <pre><code class="python" data-trim style="font-size: 1.3em">
hash ^= hash >> uint32(15)
hash *= primes[1]
hash ^= hash >> uint32(13)
hash *= primes[2]
hash ^= hash >> uint32(16)

return hash
            </code></pre>
            <aside class="notes">
              Finally, a post processing step. Notice how these all look pretty
              similar now you know how to break them down?
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (s)</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>3.337822</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>4.032726</td>
                  <td>12 (0.005%)</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              No number collisions, which probably indicates the type of data
              xxHash was most tested with.
            </aside>
          </section>

          <section>
            <h2>xxHash</h2>
            <img src="images/xxhash32.png">
          </section>
        </section>

        <section>
          <section>
            <h1 style="font-size: 2.5em">SuperFastHash</h1>
            <aside class="notes">
              All these good hash functions are boring. Let's look at what
              happens when you use a bad function. To quote NonCryptoHashZoo:
              SuperFastHash is the quintessential example of how easy it is to
              go wrong when making your own hash function even if you're
              incredibly smart.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="python" data-trim style="font-size: 0.38em">
def superfasthash(data: bytes, seed: uint32) -> uint32:
    hash = seed + uint32(len(data))

    i = 0
    while i < len(data):
        c = data[i:i+4]
        i += 4

        if len(c) == 4:
            high = uint32(unpack("=H", c[0:2])[0])
            low = uint32(unpack("=H", c[2:4])[0])

            hash += high
            tmp = (low << uint32(11)) ^ hash
            hash = (hash << uint32(16)) ^ tmp
            hash += hash >> uint32(11)
        elif len(c) == 3:
            high = uint32(unpack("=H", c[0:2])[0])
            low = uint32(unpack("=B", c[2:])[0])

            hash += high
            hash ^= hash << uint32(16)
            hash ^= low << uint32(18)
            hash += hash >> uint32(11)
        elif len(c) == 2:
            hash += uint32(unpack("=H", c)[0])
            hash ^= hash << uint32(11)
            hash += hash >> uint32(17)
        elif len(c) == 1:
            hash += uint32(unpack("=B", c)[0])
            hash ^= hash << uint32(10)
            hash += hash >> uint32(1)

    hash ^= hash << uint32(3)
    hash += hash >> uint32(5)
    hash ^= hash << uint32(4)
    hash += hash >> uint32(17)
    hash ^= hash << uint32(25)
    hash += hash >> uint32(6)

    return hash
            </code></pre>
            <aside class="notes">
              Interesting: there's no initial state besides the seed and the
              length of the input.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="python" data-trim style="font-size: 1.3em">
high = uint32(unpack("=H", c[0:2])[0])
low = uint32(unpack("=H", c[2:4])[0])

hash += high
tmp = (low << uint32(11)) ^ hash
hash = (hash << uint32(16)) ^ tmp
hash += hash >> uint32(11)
            </code></pre>
            <aside class="notes">
              There are four different mixing functions for the 4, 3, 2 and 1
              byte cases, but let's focus on the 4 byte version. There are some
              gymnastics here around bitshifting, but note that the first and
              last shift amounts are the same.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <pre><code class="python" data-trim style="font-size: 1.3em">
hash ^= hash << uint32(3)
hash += hash >> uint32(5)
hash ^= hash << uint32(4)
hash += hash >> uint32(17)
hash ^= hash << uint32(25)
hash += hash >> uint32(6)

return hash
            </code></pre>
            <aside class="notes">
              Probably because of this, there's a lot of shifting in the post
              processing. The problem is that the damage has been done by now:
              the 4 byte loop often collapses into the same state, and then
              you're going to end up with basically the same output.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (s)</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>2.195209</td>
                  <td>23946 (10.152%)</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>2.609869</td>
                  <td>54 (0.023%)</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              Oh. Oh dear.
            </aside>
          </section>

          <section>
            <h2>SuperFastHash</h2>
            <img src="images/superfasthash.png">
            <aside class="notes">
              See that stripe down the right hand side? That's not good. That's
              a lot of values collapsing into the same buckets.
            </aside>
          </section>

          <section>
            <h2>JSHash</h2>
            <img src="images/jshash.png">
            <aside class="notes">
              Of course, it could be worse. I won't go through the
              implementation of this one, but this is the output of JSHash
              (Justin Sobel) with the numbers input.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1>CRC32</h1>
            <aside class="notes">
              Finally, there is the venerable CRC32. The Cyclic Redundancy
              Check family of functions rely on polynomial division to generate
              a checksum. There's serious maths here. I don't know if you're
              ready for the implementation...
            </aside>
          </section>

          <section>
            <h2>CRC32</h2>
            <pre><code class="python" data-trim style="font-size: 1.4em">
import zlib

def crc32(data: bytes) -> int:
    return zlib.crc32(data) & 0xffffffff
            </code></pre>
            <aside class="notes">
              (pause) So, why wouldn't you use this all the time? Actually, you
              might. It's not that bad.
            </aside>
          </section>

          <section>
            <h2>CRC32</h2>
            <table>
              <thead>
                <tr>
                  <th>Corpus</th>
                  <th>CPU time (s)</th>
                  <th>Collisions</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Numbers</td>
                  <td>0.576802</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>Words</td>
                  <td>0.572763</td>
                  <td>8 (0.003%)</td>
                </tr>
              </tbody>
            </table>
            <aside class="notes">
              Really, that's pretty good. The word collisions are potentially
              an issue, but it's still above average. The only other issue is
              memory usage: CRC32 uses a lookup table and keeps more in memory,
              but unless you're on the $7 Python computer, you should be fine.
            </aside>
          </section>
        </section>

        <section>
          <section>
            <h1 style="font-size: 3em">Conclusions</h1>
          </section>
          
          <section>
            <h2>Know your environment</h2>
            <aside class="notes">
              MurmurHash3 and xxHash smoke every other algorithm when
              implemented in (OK) C or C++, because they exploit how CPUs
              behave when you're writing at that level. They use cache locality
              and read alignment to their advantage. In Python, though, that's
              just overhead: the byte at a time approach is actually faster
              because of the way the bytes type is implemented, and other
              algorithms can be simpler.
            </aside>
          </section>

          <section>
            <h2>Know your requirements</h2>
            <aside class="notes">
              Understand how many collisions you're willing to bear. The best
              way to figure this out is to implement and test with sample data:
              hash functions are easy to implement, and you can test output
              using sets. If you can deal with a few more collisions, there are
              speedier options, like CRC32.
            </aside>
          </section>

          <section>
            <h2>Respect the standard library</h2>
            <aside class="notes">
              The C CRC32 implementation kills everything else, even though CRC32 isn't considered a fast algorithm in general. If you're calling hash functions a lot and don't want to write C yourself, use what Python gives you. It's free!
            </aside>
          </section>
        </section>

        <section>
          <h2>Thank you!</h2>
          <h3>Questions?</h3>
          <a href="https://twitter.com/LGnome">@LGnome</a>
        </section>
      </div>

		</div>

		<script src="reveal.js/lib/js/head.min.js"></script>
		<script src="reveal.js/js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: false,
				progress: false,
				history: true,
				center: true,
        width: 1280,
        height: 720,

				transition: 'fade', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
<!-- vim: set nocin ai et ts=2 sw=2: -->
